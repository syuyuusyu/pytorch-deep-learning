{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "import torchvision \n",
    "from  torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import icecream as ic\n",
    "from IPython.display import clear_output,display\n",
    "\n",
    "train_data = datasets.FashionMNIST(root='data',train=True,download=True,transform=ToTensor(),target_transform=None)\n",
    "test_data = datasets.FashionMNIST(root='data',train=False,download=True,transform=ToTensor())\n",
    "\n",
    "device = 'cuda'\n",
    "print(device)\n",
    "train_loader = DataLoader(train_data,batch_size=64,shuffle=True)\n",
    "test_loader = DataLoader(test_data,batch_size=64,shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28 *28,64),\n",
    "    nn.BatchNorm1d(num_features=64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,16),\n",
    "    nn.BatchNorm1d(num_features=16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16,len(train_data.classes)),\n",
    "    #nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "class CustomModelWithConv(nn.Module):\n",
    "    def __init__(self, weight_decay=1e-4):\n",
    "        super(CustomModelWithConv, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * 14 * 14, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, len(train_data.classes))\n",
    "        )\n",
    "\n",
    "        # 添加L2正则化\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def l2_regularization222(self):\n",
    "        l2_reg = torch.tensor(0.0).to(device)\n",
    "        for param in self.parameters():\n",
    "            if len(param.shape) > 1:  # 仅对权重矩阵应用 L2 正则化\n",
    "                l2_reg += torch.norm(param, p='fro')  # 计算 Frobenius 范数\n",
    "        return self.weight_decay * l2_reg\n",
    "    \n",
    "module = CustomModelWithConv()\n",
    "    \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "optimizer = torch.optim.Adam(params=module.parameters(),lr = 0.0001, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.2)\n",
    "\n",
    "from util import accuracy_fn,train_step,test_step\n",
    "\n",
    "\n",
    "\n",
    "best_loss = float('inf')\n",
    "patience= 10\n",
    "current_patience = 0\n",
    "epochs = 100\n",
    "train_result = []\n",
    "test_result = []\n",
    "\n",
    "test_losses= []\n",
    "test_accs = []\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 8), gridspec_kw={'height_ratios': [1, 1]})\n",
    "#plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss,train_acc = train_step(module=module,data_loader=train_loader,loss_fn=loss_fn,optimizer=optimizer,device=device,accuracy_fn=accuracy_fn)\n",
    "    scheduler.step()\n",
    "    test_loss,test_acc = test_step(module=module,data_loader= test_loader,loss_fn= loss_fn,device=device,accuracy_fn=accuracy_fn)\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        current_patience = 0\n",
    "    else:\n",
    "        current_patience += 1\n",
    "\n",
    "    train_result.append((epoch,train_loss,train_acc))\n",
    "    train_losses.append(train_loss.detach().cpu().numpy())\n",
    "    #train_losses.append(train_loss.cpu())\n",
    "    train_accs.append(train_acc)\n",
    "    test_result.append((epoch,test_loss,test_acc))\n",
    "    test_losses.append(test_loss.detach().cpu().numpy())\n",
    "    test_accs.append(test_acc)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    ax1.plot(train_losses, )\n",
    "    ax2.plot(test_losses, )\n",
    "    ax3.plot(train_accs)\n",
    "    ax4.plot(test_accs)\n",
    "    ax1.set_title(f'Train Loss={[ np.round(item,4) for item in train_losses[-5:]]}')\n",
    "    ax2.set_title(f'Test Loss={[ np.round(item,4) for item in test_losses[-5:]]}')\n",
    "    ax3.set_title(f'Trian Accuracy={[ round(item,4) for item in train_accs[-5:]]}')\n",
    "    ax4.set_title(f'Test Accuracy={[ round(item,4) for item in test_accs[-5:]]}')\n",
    "    display(fig)\n",
    "    end_time = time.time()\n",
    "    print(f'-------epoch------:{epoch} time:{(end_time - start_time):.2f}s')\n",
    "    if current_patience == patience:\n",
    "        print(f'Early stopping! No improvement for {patience} consecutive epochs.')\n",
    "        print(f\"train loss:{[ np.round(item,4) for item in test_losses]}\")\n",
    "        print(f\"test loss:{[ np.round(item,4) for item in test_losses]}\")\n",
    "        break\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"last 10 loss:{[ np.round(item,4) for item in test_losses[-10:]]}\")\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_lable,loss_lable,acc_lable = zip(*train_result)\n",
    "loss_lable = [item.detach().cpu().numpy() for item in loss_lable]\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(epoch_lable, loss_lable, label='Train Loss', marker='o')\n",
    "#plt.plot(epoch_lable, acc_lable, label='Train acc', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(epoch_lable, acc_lable, label='Train acc', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('ACC')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_lable,test_loss_lable,test_acc_lable = zip(*test_result)\n",
    "test_loss_lable = [item.detach().cpu().numpy() for item in test_loss_lable]\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(test_epoch_lable, test_loss_lable, label='Test Loss', marker='o')\n",
    "#plt.plot(test_epoch_lable, test_acc_lable, label='Test acc', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "#plt.plot(epoch_lable, loss_lable, label='Test Loss', marker='o')\n",
    "plt.plot(test_epoch_lable, test_acc_lable, label='Test acc', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_data[0]\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "plt.imshow(image.squeeze()) # image shape is [1, 28, 28] (colour channels, height, width)\n",
    "plt.title(label);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col = 4,4\n",
    "figure = plt.figure(figsize=(9,9))\n",
    "class_names = train_data.classes\n",
    "for i in range(1,row* col+1):\n",
    "    index = torch.randint(0,len(train_data),size=[1]).item()\n",
    "    image, label = train_data[index]\n",
    "    figure.add_subplot(row, col, i)\n",
    "    plt.imshow(image.squeeze())\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False);\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
